{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ratsgo/nlpbook/blob/master/examples/basic/tokenization.ipynb","timestamp":1672842934226}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f6a7af947af646548f11c6d2c3c2bd15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10b84e9db68643138b3d8fafd8822ff3","IPY_MODEL_35ff31ca8b6f4485abe390f6ff64cdd1","IPY_MODEL_b37ed0b6bf6744108ab70139ba38931b"],"layout":"IPY_MODEL_321201c9f1fe4acf8f0e3826bc309010"}},"10b84e9db68643138b3d8fafd8822ff3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a332fee1bf9349e08b945c77926afed4","placeholder":"​","style":"IPY_MODEL_bd49512e0c9b4391a90180b96ee6c7e0","value":"vocab.txt: 100%"}},"35ff31ca8b6f4485abe390f6ff64cdd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f93fbbfbef9f40e388238adbe254187e","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0013768cc7347aab55f2f368fe1021b","value":77779}},"b37ed0b6bf6744108ab70139ba38931b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7619c5ea9b64437199c0fab6144f387f","placeholder":"​","style":"IPY_MODEL_7ac479227ef24c1c9a2cd2f246552495","value":" 77.8k/77.8k [00:00&lt;00:00, 3.75MB/s]"}},"321201c9f1fe4acf8f0e3826bc309010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a332fee1bf9349e08b945c77926afed4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd49512e0c9b4391a90180b96ee6c7e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f93fbbfbef9f40e388238adbe254187e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0013768cc7347aab55f2f368fe1021b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7619c5ea9b64437199c0fab6144f387f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ac479227ef24c1c9a2cd2f246552495":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7387f7bbad54517a71560f8e560ad18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d08c7e1cfc784b3cb7384a8fbc1fba72","IPY_MODEL_58cfbef2906743d292436a555cd820a7","IPY_MODEL_429218b026ce44e9b68fcf1db9f52ae8"],"layout":"IPY_MODEL_698d359589fd4548a1664f8700b7d9b2"}},"d08c7e1cfc784b3cb7384a8fbc1fba72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9bb898c89944618654556ec98e5ede","placeholder":"​","style":"IPY_MODEL_1fb9477e29144559bc7d9f0c217e7fab","value":"tokenizer_config.json: 100%"}},"58cfbef2906743d292436a555cd820a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2ecd84968e74275be32eb04480f3ba5","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d89159b265bd4f748783fdb97ed3a051","value":51}},"429218b026ce44e9b68fcf1db9f52ae8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad54e530829d4a089b8a9a13b7236100","placeholder":"​","style":"IPY_MODEL_c3b381b28b1a483e93de3c88a5a7cc32","value":" 51.0/51.0 [00:00&lt;00:00, 4.34kB/s]"}},"698d359589fd4548a1664f8700b7d9b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d9bb898c89944618654556ec98e5ede":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb9477e29144559bc7d9f0c217e7fab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2ecd84968e74275be32eb04480f3ba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d89159b265bd4f748783fdb97ed3a051":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad54e530829d4a089b8a9a13b7236100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3b381b28b1a483e93de3c88a5a7cc32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb9869d10b584207939349c40f37cccf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78e2b5a9636743b6a9191ca5baaf94f2","IPY_MODEL_f7a4e019638b492aa18fcdcf4e58c1cb","IPY_MODEL_466b8d75709e4acf8b63191c2efda079"],"layout":"IPY_MODEL_9edd41a4490a4738bf0bd49f9cadd05a"}},"78e2b5a9636743b6a9191ca5baaf94f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75346363f2b34d5fa21c6e5baeacfd23","placeholder":"​","style":"IPY_MODEL_52bed9c8be104afb96cf6003d8a14f3c","value":"config.json: 100%"}},"f7a4e019638b492aa18fcdcf4e58c1cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b627c3165774fa8a6cc724df5419242","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90d361c75258489cabdb16a13faf01c2","value":426}},"466b8d75709e4acf8b63191c2efda079":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d45a2fce19f64a26a4e7ef5f4fab8d67","placeholder":"​","style":"IPY_MODEL_4566734dc7d948a79c2165608e69a109","value":" 426/426 [00:00&lt;00:00, 38.1kB/s]"}},"9edd41a4490a4738bf0bd49f9cadd05a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75346363f2b34d5fa21c6e5baeacfd23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52bed9c8be104afb96cf6003d8a14f3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b627c3165774fa8a6cc724df5419242":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90d361c75258489cabdb16a13faf01c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d45a2fce19f64a26a4e7ef5f4fab8d67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4566734dc7d948a79c2165608e69a109":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"EpjMKSVWs6B2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707374859291,"user_tz":-540,"elapsed":17724,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"877e8de7-7b6b-4acc-f58c-71d7d9936353"},"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"t8TJkXkpDnSq","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1707374878759,"user_tz":-540,"elapsed":18043,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"84099783-5c15-4deb-a5d4-11c9344a4fb6"},"source":["!pip install ratsnlp"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ratsnlp\n","  Downloading ratsnlp-1.0.53-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m845.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch-lightning==1.6.1 (from ratsnlp)\n","  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.28.1 (from ratsnlp)\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Korpora>=0.2.0 (from ratsnlp)\n","  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ratsnlp) (2.2.5)\n","Collecting flask-ngrok>=0.0.25 (from ratsnlp)\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Collecting flask-cors>=3.0.10 (from ratsnlp)\n","  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (1.23.5)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2.1.0+cu121)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (6.0.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2023.6.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2.12.0)\n","Collecting torchmetrics>=0.4.1 (from pytorch-lightning==1.6.1->ratsnlp)\n","  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1 (from pytorch-lightning==1.6.1->ratsnlp)\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (23.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (0.20.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->ratsnlp) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1->ratsnlp)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (3.0.1)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.4->ratsnlp) (8.1.7)\n","Collecting dataclasses>=0.6 (from Korpora>=0.2.0->ratsnlp)\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora>=0.2.0->ratsnlp) (2.0.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (3.9.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=1.1.4->ratsnlp) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->ratsnlp) (2024.2.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.60.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.5.2)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.7.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.42.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (3.2.1)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (2.1.0)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics>=0.4.1->pytorch-lightning==1.6.1->ratsnlp)\n","  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (4.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.*->pytorch-lightning==1.6.1->ratsnlp) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.2.2)\n","Installing collected packages: tokenizers, dataclasses, pyDeprecate, lightning-utilities, Korpora, transformers, torchmetrics, flask-ngrok, flask-cors, pytorch-lightning, ratsnlp\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.1\n","    Uninstalling tokenizers-0.15.1:\n","      Successfully uninstalled tokenizers-0.15.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.2\n","    Uninstalling transformers-4.35.2:\n","      Successfully uninstalled transformers-4.35.2\n","Successfully installed Korpora-0.2.0 dataclasses-0.6 flask-cors-4.0.0 flask-ngrok-0.0.25 lightning-utilities-0.10.1 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 ratsnlp-1.0.53 tokenizers-0.13.3 torchmetrics-1.3.0.post0 transformers-4.28.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dataclasses"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"-Jsq7yrjWYTB"},"source":["### GPT 입력값 만들기\n","\n","GPT 입력값을 만들려면 토크나이저부터 준비해야 하며 아래 코드를 수행하면 GPT 모델이 사용하는 토크나이저를 초기화할 수 있다. 먼저 자신의 구글 드라이브 경로(/gdrive/My Drive/nlpbook/bbpe)에는 이전 실습에서 만든 바이트 기준 BPE 어휘 집합(vocab.json)과 바이그램 쌍의 병합 우선순위(merge.txt)가 있어야 합니다."]},{"cell_type":"code","metadata":{"id":"aJRVVpC-WyIc"},"source":["# GPT 토크나이저 선언: GPT2Tokenizer'는 텍스트를 GPT-2 모델이 이해할 수 있는 형식으로 변환\n","# 여기에는 텍스트를 토큰(단어 또는 하위 단어)으로 분할하고 이러한 토큰을 모델이 처리에 사용하는 숫자 ID로 변환하는 작업이 포함\n","from transformers import GPT2Tokenizer # transformers 라이브러리에서 GPT2Tokenizer 클래스를 가져온다.\n","tokenizer_gpt = GPT2Tokenizer.from_pretrained(\"/gdrive/My Drive/nlpbook/bbpe\") # 사전 훈련된 토크나이저 로드\n","tokenizer_gpt.pad_token = \"[PAD]\" # 토크나이저는 패딩 목적으로 사용할 토큰을 알아야 하기 때문에 'pad_token'을 명시적으로 설정하는 것이 필요"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8n3JlkUbZobu"},"source":["예시 문장 세 개를 각각 토큰화해보겠습니다."]},{"cell_type":"code","metadata":{"id":"Vp48wVBIZtYj"},"source":["# 토크나이저로 토큰화하기\n","sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","tokenized_sentences = [tokenizer_gpt.tokenize(sentence) for sentence in sentences]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8-ahPBg-Zx71"},"source":["토큰화 결과를 확인합니다."]},{"cell_type":"code","metadata":{"id":"__DWz4djZz_u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707374910152,"user_tz":-540,"elapsed":285,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"c833d747-05f0-4bc5-aefd-d89d837c2825"},"source":["# GPT 모델은 바이트 기준 BPE를 적용\n","tokenized_sentences"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['ìķĦ', 'ĠëįĶë¹Ļ', '..', 'Ġì§Ħì§ľ', 'Ġì§ľì¦ĿëĤĺ', 'ëĦ¤ìļĶ', 'Ġëª©ìĨĮë¦¬'],\n"," ['íĿł',\n","  '...',\n","  'íı¬ìĬ¤íĦ°',\n","  'ë³´ê³ł',\n","  'Ġì´ĪëĶ©',\n","  'ìĺģíĻĶ',\n","  'ì¤Ħ',\n","  '....',\n","  'ìĺ¤ë²Ħ',\n","  'ìĹ°ê¸°',\n","  'ì¡°ì°¨',\n","  'Ġê°Ģë³į',\n","  'ì§Ģ',\n","  'ĠìķĬ',\n","  'êµ¬ëĤĺ'],\n"," ['ë³Ħë£¨', 'Ġìĺ', 'Ģëĭ¤', '..']]"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["GPT 모델 입력 만들기"],"metadata":{"id":"Ee8tN4sQWOzk"}},{"cell_type":"code","metadata":{"id":"ATwWfngCXQXK"},"source":["#  GPT 모델 입력\n","sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","batch_inputs = tokenizer_gpt(\n","    sentences,\n","    padding=\"max_length\", # 문자의 최대 길이에 맞춰 패딩. max_length 매개변수로 지정된 최대 길이로 균일하게 시퀀스를 채우도록 지시\n","    max_length=12, # 문장의 토큰 기준 최대 길이. 문장이 12개 이상의 토큰으로 변환되면 잘림. 더 적은 수로 변환되면 패딩 토큰으로 채워진다.\n","    truncation=True, # 문장 잘림 허용 옵션\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9g0tJ9uXj6O"},"source":["`batch_inputs`의 내용을 확인\n","- input_ids: 문장의 토큰화된 표현을 포함하며, 각 토큰은 토크나이저 어휘에서 해당하는 ID로 대체.\n","- attention_mask: 각 위치에 토큰이 존재하는지를 나타내는 이진 마스크입니다. 토큰이 존재하면 1, 토큰이 존재하지 않으면(즉, 패딩인 경우) 0입니다. 이는 모델이 실제 데이터와 패딩을 구별할 수 있도록 도와준다."]},{"cell_type":"code","metadata":{"id":"T4pnC6DjXkv6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707374922824,"user_tz":-540,"elapsed":300,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"b05dd023-ca45-43a1-9918-9d342b408fbd"},"source":["batch_inputs.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"XJBRdJegXsZd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707374926653,"user_tz":-540,"elapsed":290,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"5faf32ec-e8d6-4db6-b8ca-8132ef31ae82"},"source":["# 'input_ids'는 토큰화 결과를 가지고 각 토큰들을 인덱스(index)로 바꾼 것\n","batch_inputs['input_ids']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[334, 2338, 263, 581, 4055, 464, 3808, 0, 0, 0, 0, 0],\n"," [3693, 336, 2876, 758, 2883, 356, 806, 422, 9875, 875, 2960, 7292],\n"," [4957, 451, 3653, 263, 0, 0, 0, 0, 0, 0, 0, 0]]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"b_XT5QTsXvBG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707374929386,"user_tz":-540,"elapsed":286,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"631d4e46-216c-4515-db95-16c398a8fb61"},"source":["# attention_mask는 일반 토큰이 자리한 곳(1)과 패딩 토큰이 자리한 곳(0)을 구분해 알려주는 장치\n","batch_inputs['attention_mask']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2LMHeadModel\n","\n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","# text = '근육이 커지기 위해서는'\n","text = '이 영화는'\n","input_ids = tokenizer.encode(text, return_tensors='pt')\n","gen_ids = model.generate(input_ids,\n","                           max_length=128,\n","                           repetition_penalty=2.0,\n","                           pad_token_id=tokenizer.pad_token_id,\n","                           eos_token_id=tokenizer.eos_token_id,\n","                           bos_token_id=tokenizer.bos_token_id,\n","                           use_cache=True)\n","generated = tokenizer.decode(gen_ids[0])\n","print(generated)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5__DRV_jmqsR","executionInfo":{"status":"ok","timestamp":1707377148660,"user_tz":-540,"elapsed":4304,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"2db7d3a1-f53a-4fd9-b2ff-c2d9419fc1b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["이 영화는 '내 이름은 김삼순'이었다.\n","김영화는 \"그동안 내가 살아온 삶의 궤적을 돌아보면서 그 속에서 내 삶을 되돌아보는 시간을 가져보고 싶었다\"고 말했다.\n","그는 이어 \"이번 영화제에서는 관객들이 직접 영화를 보고 느낄 수 있는 기회를 마련했다\"며 기대감을 나타냈다.\n","이날 상영된 작품은 총 4편.</d> 지난해 12월 31일부터 올 1월 1일까지 진행된 이번 공모전은 ‘2018 대한민국 디자인대상’ 수상작과 우수작을 선정하는 방식으로 진행됐다.\n","공모전 주제는 △디자인에 대한 관심과 열정, 창의성, 혁신성 등 3개 분야다.\n","수상작은 ▲‘디자인의 미래, 우리\n"]}]},{"cell_type":"markdown","source":["KoGPT2 (한국어 GPT-2) Ver 2.0"],"metadata":{"id":"TjzpguOlerjz"}},{"cell_type":"code","source":["from transformers import GPT2TokenizerFast\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n","pad_token='<pad>', mask_token='<mask>')"],"metadata":{"id":"UZLOCFpzef6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","batch_inputs = tokenizer(\n","    sentences,\n","    padding=\"max_length\", # 문자의 최대 길이에 맞춰 패딩. max_length 매개변수로 지정된 최대 길이로 균일하게 시퀀스를 채우도록 지시\n","    max_length=12, # 문장의 토큰 기준 최대 길이. 문장이 12개 이상의 토큰으로 변환되면 잘림. 더 적은 수로 변환되면 패딩 토큰으로 채워진다.\n","    truncation=True, # 문장 잘림 허용 옵션\n","    return_tensors='tf'\n",")"],"metadata":{"id":"bfh6mWiafAeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_inputs.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJ1Kwl7pfngm","executionInfo":{"status":"ok","timestamp":1707375233327,"user_tz":-540,"elapsed":285,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"ad98f648-1389-4fbc-d169-836c9fcd1140"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["batch_inputs['input_ids']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clTOpbA3fsSZ","executionInfo":{"status":"ok","timestamp":1707375252438,"user_tz":-540,"elapsed":3,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"a4c7f133-2756-471c-c1a9-849b38f3689c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 12), dtype=int32, numpy=\n","array([[ 9050,  9267,  7700,  9705, 23971, 12870,  8262,  7055,  7098,\n","         8084, 48213,     3],\n","       [19243, 29045,  8658, 11211, 11213,  9206,  7301, 14558,  8239,\n","        10765,  8052,  7621],\n","       [ 9686,  7445,   739, 26049,   389,     3,     3,     3,     3,\n","            3,     3,     3]], dtype=int32)>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["batch_inputs['attention_mask']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ex6kseeLfwp6","executionInfo":{"status":"ok","timestamp":1707375270855,"user_tz":-540,"elapsed":320,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"38dae959-e841-4d3a-e4cc-02d4229d0a94"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 12), dtype=int32, numpy=\n","array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2LMHeadModel\n","\n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","# text = '근육이 커지기 위해서는'\n","text = '피부의 조직이 괴사된다면'\n","input_ids = tokenizer.encode(text, return_tensors='pt')\n","gen_ids = model.generate(input_ids,\n","                           max_length=128,\n","                           repetition_penalty=2.0,\n","                           pad_token_id=tokenizer.pad_token_id,\n","                           eos_token_id=tokenizer.eos_token_id,\n","                           bos_token_id=tokenizer.bos_token_id,\n","                           use_cache=True)\n","generated = tokenizer.decode(gen_ids[0])\n","print(generated)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F29Sz9VNhghn","executionInfo":{"status":"ok","timestamp":1707376507242,"user_tz":-540,"elapsed":4227,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"c0bfa898-dca9-4da5-898b-15a02cd661c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["피부의 조직이 괴사된다면 그 원인은 아직 밝혀지지 않았다.\n","그러나 이 같은 사실은 이미 여러 차례 밝혀졌었다.\n","이번 연구에서는 뇌졸중 환자의 약 80%가 알츠하이머병이라는 사실을 밝혀냈다.\n","알츠는 신경전달물질인 아세틸콜린의 분비를 촉진해 뇌의 혈류량을 증가시킨다.\n","또한 혈관 내피세포의 기능을 활성화시켜 동맥경화를 예방한다.\n","뇌혈관이 좁아지면 혈액순환에 장애가 생겨 심혈관질환을 유발할 수 있다.\n","따라서 이번 연구는 심장마비나 당뇨병, 고혈압, 고지혈, 비만, 흡연, 음주, 흡연 등 다양한 위험요인을 가진 환자들에게 도움이 될 것으로 기대된다.\n","연구팀은 “심장\n"]}]},{"cell_type":"markdown","metadata":{"id":"IzWd3u-vXz9c"},"source":["### BERT 입력값 만들기\n","\n","- BERT (Bidirectional Encoder Representations from Transformers)는 다양한 자연어 처리(NLP) 작업에서 사용되는 인기 있는 모델. BertTokenizer는 특히 BERT 모델에 적합한 텍스트 토큰화 도구\n","- BERT 모델 입력값을 만들려면 자신의 구글 드라이브 경로(`/gdrive/My Drive/nlpbook/wordpiece`)에 워드피스 어휘집합 구축 결과(`vocab.txt`)가 있어야 한다. 이미 만들어 놓은 워드피스 어휘집합을 포함한 BERT 토크나이저를 `tokenizer_bert`라는 변수로 선언한다."]},{"cell_type":"code","metadata":{"id":"JTFeKKzJX-O7"},"source":["# BertTokenizer는 BERT 모델이 이해할 수 있는 형태로 텍스트를 토큰화하는 데 사용\n","from transformers import BertTokenizer\n","tokenizer_bert = BertTokenizer.from_pretrained(  # 사전 훈련된 토크나이저 로드\n","    \"/gdrive/My Drive/nlpbook/wordpiece\",\n","    do_lower_case=False, # 토크나이저가 텍스트를 소문자로 변환하지 않도록 지정\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pcxOXJxaER5"},"source":["예시 문장 세 개를 각각 토큰화해보겠습니다."]},{"cell_type":"code","metadata":{"id":"c9AzWXcvaJKH"},"source":["sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","tokenized_sentences = [tokenizer_bert.tokenize(sentence) for sentence in sentences]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xJhOHq-maNLw"},"source":["토큰화 결과를 확인합니다."]},{"cell_type":"code","metadata":{"id":"HdzBTLFPaPFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707377695171,"user_tz":-540,"elapsed":315,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"ef2c4376-0e0b-4162-df21-88d506396efc"},"source":["print(tokenized_sentences)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['아', '더빙', '.', '.', '진짜', '짜증나', '##네요', '목소리'], ['흠', '.', '.', '.', '포스터', '##보고', '초딩', '##영화', '##줄', '.', '.', '.', '.', '오버', '##연기', '##조차', '가볍', '##지', '않', '##구나'], ['별루', '였다', '.', '.']]\n"]}]},{"cell_type":"markdown","metadata":{"id":"cMxTUoowYHb2"},"source":["이번 배치의 크기가 3이라고 가정하고 이번 배치의 입력값을 만들어 보겠습니다."]},{"cell_type":"code","metadata":{"id":"G_sFosQjYIE3"},"source":["sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","batch_inputs = tokenizer_bert(\n","    sentences,\n","    padding=\"max_length\", # max_length 매개변수로 지정된 최대 길이와 동일한 길이로 채워지도록 보장\n","    max_length=12, # 토큰화된 각 시퀀스가 ​​가져야 하는 고정 길이를 설정\n","    truncation=True, # 토크나이저가 max_length를 초과하는 시퀀스를 자를 수 있도록 허용\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ohNW5R3zYOW5"},"source":["`batch_inputs`의 내용을 확인해보겠습니다."]},{"cell_type":"code","metadata":{"id":"RZiMSoaKYTUX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707144595134,"user_tz":-540,"elapsed":18,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"17dd0c04-3dc0-41be-cfa9-91fe47f8ad5b"},"source":["# # BERT 모델 세 가지의 입력값\n","batch_inputs.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["- [CLS] 토큰은 \"분류\"를 나타내며 모든 입력 시퀀스의 첫 번째 토큰으로 사용. BERT가 분류 작업(예: 감정 분석, 의도 감지)에 사용되는 경우 이 토큰의 표현은 분류 작업의 집계 시퀀스 표현으로 사용된다. 본질적으로 이는 전체 입력 시퀀스의 의미를 요약하는 역할\n","- [SEP] 토큰은 \"구분 기호\"를 나타내며 입력 내에서 개별 세그먼트를 구분하는 데 사용. 이는 질문 답변(모델이 질문과 맥락을 구별해야 하는 경우) 또는 문장 쌍 작업(예: 모델이 두 문장 간의 관계를 결정하는 자연어 추론)과 같은 여러 입력 시퀀스가 ​​포함된 작업에 특히 중요\n","- 예를 들어 문장 쌍 분류 작업에서 입력은 [CLS] 문장 1 [SEP] 문장 2 [SEP]와 같을 수 있으며 [SEP] 토큰은 첫 번째 문장의 끝을 표시하고 구분"],"metadata":{"id":"fYwQY7_Yw6l9"}},{"cell_type":"code","metadata":{"id":"4pWaGuSdYZGR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707144597778,"user_tz":-540,"elapsed":362,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"93f75018-d01e-4bab-ba7f-f9a55d3cd39b"},"source":["# 토큰 인덱스 시퀀스\n","# 문장 앞에 2, 끝에 3이 붙는 것은 각각 [CLS], [SEP] 라는 토큰에 대응하는 인덱스\n","batch_inputs['input_ids']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[2, 620, 2631, 16, 16, 1993, 3678, 1990, 3323, 3, 0, 0],\n"," [2, 997, 16, 16, 16, 2609, 2045, 2796, 1981, 1241, 16, 3],\n"," [2, 3274, 9509, 16, 16, 3, 0, 0, 0, 0, 0, 0]]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"djtA4xkIYbOk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707144603581,"user_tz":-540,"elapsed":315,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"3863d7a2-ae16-4e64-f521-44d354b1d8d0"},"source":["# BERT의 attention_mask는 GPT와 마찬가지로 일반 토큰이 자리한 곳(1)과 패딩 토큰이 자리한 곳(0)을 구분\n","batch_inputs['attention_mask']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"cVR15VXZYoTZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707144623945,"user_tz":-540,"elapsed":546,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"dd48599e-51eb-46a4-f7b9-bd8822bc5145"},"source":["# token_type_ids는 세그먼트(segment)에 해당하는 것으로 모두 0\n","# BERT 모델은 기본적으로 문서(혹은 문장) 2개를 입력받는데, token_type_ids로 구분.\n","# 첫 번째 세그먼트(문서 혹은 문장)에 해당하는 token_type_ids는 0, 두 번째 세그먼트는 1\n","batch_inputs['token_type_ids']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["사전 훈련된 KoBERT 모델 사용"],"metadata":{"id":"vvkD4VaYpG9R"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","# KoBERT 모델의 사전 훈련된 토크나이저 로드\n","tokenizer_kobert = BertTokenizer.from_pretrained(\n","    \"monologg/kobert\",  # Hugging Face 모델 허브에서 KoBERT 모델을 지정\n","    do_lower_case=False,  # 토크나이저가 텍스트를 소문자로 변환하지 않도록 지정\n",")\n","\n","# 사용 예시\n","text = \"한국어 모델을 사용하여 텍스트 처리를 해봅시다.\"\n","input_ids = tokenizer_kobert.encode(text, add_special_tokens=True)\n","print(input_ids)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["f6a7af947af646548f11c6d2c3c2bd15","10b84e9db68643138b3d8fafd8822ff3","35ff31ca8b6f4485abe390f6ff64cdd1","b37ed0b6bf6744108ab70139ba38931b","321201c9f1fe4acf8f0e3826bc309010","a332fee1bf9349e08b945c77926afed4","bd49512e0c9b4391a90180b96ee6c7e0","f93fbbfbef9f40e388238adbe254187e","b0013768cc7347aab55f2f368fe1021b","7619c5ea9b64437199c0fab6144f387f","7ac479227ef24c1c9a2cd2f246552495","f7387f7bbad54517a71560f8e560ad18","d08c7e1cfc784b3cb7384a8fbc1fba72","58cfbef2906743d292436a555cd820a7","429218b026ce44e9b68fcf1db9f52ae8","698d359589fd4548a1664f8700b7d9b2","8d9bb898c89944618654556ec98e5ede","1fb9477e29144559bc7d9f0c217e7fab","e2ecd84968e74275be32eb04480f3ba5","d89159b265bd4f748783fdb97ed3a051","ad54e530829d4a089b8a9a13b7236100","c3b381b28b1a483e93de3c88a5a7cc32","cb9869d10b584207939349c40f37cccf","78e2b5a9636743b6a9191ca5baaf94f2","f7a4e019638b492aa18fcdcf4e58c1cb","466b8d75709e4acf8b63191c2efda079","9edd41a4490a4738bf0bd49f9cadd05a","75346363f2b34d5fa21c6e5baeacfd23","52bed9c8be104afb96cf6003d8a14f3c","7b627c3165774fa8a6cc724df5419242","90d361c75258489cabdb16a13faf01c2","d45a2fce19f64a26a4e7ef5f4fab8d67","4566734dc7d948a79c2165608e69a109"]},"id":"RzI_QA18oVWx","executionInfo":{"status":"ok","timestamp":1707377526185,"user_tz":-540,"elapsed":812,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"c7652083-3547-4695-95d2-566881f17210"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a7af947af646548f11c6d2c3c2bd15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7387f7bbad54517a71560f8e560ad18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb9869d10b584207939349c40f37cccf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[2, 0, 0, 0, 0, 0, 0, 54, 3]\n"]}]},{"cell_type":"code","source":["sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","tokenized_sentences = [tokenizer_kobert.tokenize(sentence) for sentence in sentences]\n","print(tokenized_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPNB78Ocolx8","executionInfo":{"status":"ok","timestamp":1707377655719,"user_tz":-540,"elapsed":287,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"4c747065-c2dd-4f26-869e-736a7abc23b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['아', '[UNK]', '.', '.', '진짜', '[UNK]', '[UNK]'], ['흠', '.', '.', '.', '[UNK]', '[UNK]', '.', '.', '.', '.', '[UNK]', '[UNK]', '[UNK]'], ['[UNK]', '였다', '.', '.']]\n"]}]},{"cell_type":"code","source":["sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","batch_inputs = tokenizer_kobert(\n","    sentences,\n","    padding=\"max_length\", # max_length 매개변수로 지정된 최대 길이와 동일한 길이로 채워지도록 보장\n","    max_length=12, # 토큰화된 각 시퀀스가 ​​가져야 하는 고정 길이를 설정\n","    truncation=True, # 토크나이저가 max_length를 초과하는 시퀀스를 자를 수 있도록 허용\n","    return_tensors='tf'\n",")\n","\n","batch_inputs.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zJQ2Hl8pQkh","executionInfo":{"status":"ok","timestamp":1707377902164,"user_tz":-540,"elapsed":297,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"37ee9129-94c2-4cc4-a21e-e8de6631dd0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["print(batch_inputs.input_ids)\n","print(batch_inputs.token_type_ids)\n","print(batch_inputs.attention_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfBbj3zwp3Hp","executionInfo":{"status":"ok","timestamp":1707377969765,"user_tz":-540,"elapsed":291,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"f57f8ae8-1c76-493d-f42f-d9318924b1c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[   2 6797    0   54   54 7347    0    0    3    1    1    1]\n"," [   2 7989   54   54   54    0    0   54   54   54   54    3]\n"," [   2    0 6946   54   54    3    1    1    1    1    1    1]], shape=(3, 12), dtype=int32)\n","tf.Tensor(\n","[[0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0]], shape=(3, 12), dtype=int32)\n","tf.Tensor(\n","[[1 1 1 1 1 1 1 1 1 0 0 0]\n"," [1 1 1 1 1 1 1 1 1 1 1 1]\n"," [1 1 1 1 1 1 0 0 0 0 0 0]], shape=(3, 12), dtype=int32)\n"]}]}]}