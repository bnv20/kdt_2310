{"cells":[{"cell_type":"markdown","source":["## 모델 구성\n","PyTorch 모델은 모델 아키텍처 정의, 손실 함수 지정, 최적화 프로그램 선택 등 여러 주요 단계가 필요하며 일반적으로 torch.nn.Module을 서브클래싱하고 __init__ 및 forward 메서드를 구현하여 정의됩니다.\n","\n","[ 데이터 준비 ]\n","\n","데이터셋을 위한 전처리 과정 정의, 로드, 훈련 데이터셋을 훈련 및 검증 세트로 분할\n","\n","[ 모델 아키텍처 정의 ]\n","\n","서브클래스 torch.nn.Module\n","모든 PyTorch 모델은 'torch.nn.Module'을 하위 클래스로 분류해야 합니다. 이 기본 클래스는 매개변수 추적 및 후크 정의와 같은 모든 모델에 대한 공통 기능을 제공합니다.\n","- __init__에서 레이어 초기화<br>\n","__init__ 메소드 내에서 모델의 레이어와 매개변수를 정의합니다. PyTorch는 완전히 연결된 레이어를 위한 'nn.Linear', 컨볼루션 레이어를 위한 'nn.Conv2d' 등과 같은 'torch.nn' 모듈에 내장된 레이어의 포괄적인 컬렉션을 제공합니다.\n","- forward 메소드 구현<br>\n","forward 방법은 모델이 입력 데이터를 처리하는 방법을 정의합니다. 여기서는 모델의 순방향 전달을 지정하고 필요에 따라 레이어를 연결하고 활성화 기능을 적용합니다.\n","\n","[ 손실 함수 지정 ]\n","- 모델을 정의한 후에는 모델의 예측이 목표 데이터와 얼마나 잘 일치하는지 측정하는 손실 함수를 지정해야 합니다. PyTorch는 'torch.nn'에서 분류 작업을 위한 'nn.CrossEntropyLoss', 회귀 작업을 위한 'nn.MSELoss'와 같은 몇 가지 일반적인 손실 함수를 제공합니다.\n","\n","[ 최적화 프로그램을 선택 ]\n","- 최적화 프로그램은 손실 함수를 최소화하기 위해 모델 매개변수를 조정합니다. PyTorch의 torch.optim 모듈에는 SGD 및 Adam과 같은 다양한 최적화 알고리즘이 포함되어 있습니다.\n","\n","[ 모델 훈련 ]\n","- 훈련에는 데이터세트 반복, 모델 예측, 손실 계산, 모델 매개변수 업데이트가 포함됩니다.\n","\n","[ 모델 평가 ]\n","- 훈련 후에는 검증 또는 테스트 세트에서 모델의 성능을 평가하여 모델이 잘 일반화되는지 확인하세요.\n","\n"],"metadata":{"id":"hJauYGy9au0i"}},{"cell_type":"markdown","source":["Q. mnist 데이터 셋에 대해서 Pytorch를 적용하여 모델 구성 변경, 조기 학습 중단을 수행하고 Bset model을 저장한 후 다시 불러와서 테스트 데이터로 평가한 결과를 출력하세요."],"metadata":{"id":"YmMFlzh80O0B"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# MNIST 데이터셋을 위한 전처리 과정 정의\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환\n","    transforms.Normalize((0.5,), (0.5,))  # 이미지를 평균 0.5, 표준편차 0.5로 정규화하여 [-1, 1] 범위로 조정\n","])\n","\n","# MNIST 데이터셋 로드\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# 훈련 데이터셋을 훈련 및 검증 세트로 분할\n","train_size = int(0.8 * len(train_dataset))  # 훈련 세트 크기를 전체의 80%로 설정\n","val_size = len(train_dataset) - train_size  # 검증 세트 크기 계산\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])  # 분할 실행\n","\n","trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","valloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# 모델 아키텍처 정의\n","class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5)  # 컨볼루션 레이어 정의 (입력 채널 1, 출력 채널 20, 커널 크기 5)\n","        self.pool = nn.MaxPool2d(2, 2)  # 맥스풀링 레이어 정의 (2x2 풀링)\n","        self.flatten = nn.Flatten()  # 텐서 평탄화\n","        self.fc1 = nn.Linear(2880, 50)  # 완전 연결 레이어 (입력 크기 2880, 출력 크기 50)\n","        self.fc2 = nn.Linear(50, 10)  # 출력 레이어 (클래스 수 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))  # ReLU 활성화 함수 적용 후 맥스풀링\n","        x = self.flatten(x)  # 평탄화\n","        x = F.relu(self.fc1(x))  # ReLU 활성화 함수 적용\n","        x = self.fc2(x)  # 최종 출력\n","        return x\n","\n","model = MyModel()  # 모델 인스턴스 생성\n","\n","# 손실 함수 및 최적화 알고리즘 지정\n","criterion = nn.CrossEntropyLoss()  # 크로스 엔트로피 손실 함수\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # SGD 최적화 알고리즘\n","\n","# 모델 훈련\n","best_val_loss = float('inf')  # 검증 손실을 추적하기 위한 변수 초기화\n","patience, trials = 5, 0  # 조기 종료 기준 설정\n","num_epochs = 20  # 에폭 수 설정\n","for epoch in range(num_epochs):\n","    model.train()  # 모델을 훈련 모드로 설정\n","    running_loss = 0.0\n","    for inputs, labels in trainloader:\n","        optimizer.zero_grad()  # 그래디언트 초기화\n","        outputs = model(inputs)  # 모델을 통한 순전파\n","        loss = criterion(outputs, labels)  # 손실 계산\n","        loss.backward()  # 역전파\n","        optimizer.step()  # 파라미터 업데이트\n","        running_loss += loss.item()\n","\n","    # 검증 단계\n","    val_loss = 0.0\n","    model.eval()  # 모델을 평가 모드로 설정\n","    with torch.no_grad():\n","        for inputs, labels in valloader:\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","    val_loss /= len(valloader)  # 평균 검증 손실 계산\n","    print(f'Epoch {epoch+1}, Train Loss: {running_loss / len(trainloader)}, Val Loss: {val_loss}')\n","\n","    # 검증 손실이 개선되었는지 확인하고 모델 저장\n","    if val_loss < best_val_loss:\n","        print(f'Validation Loss Decreased({best_val_loss:.6f}--->{val_loss:.6f}) \\t Saving The Model')\n","        best_val_loss = val_loss\n","        trials = 0\n","        torch.save(model.state_dict(), 'best_model.pth')  # 모델 저장\n","    else:\n","        trials += 1\n","        if trials >= patience:  # 조기 종료 조건 충족 확인\n","            print(\"Early stopping triggered\")\n","            break\n","\n","# 최고의 모델을 불러와서 평가\n","model.load_state_dict(torch.load('best_model.pth'))  # 모델 상태 불러오기\n","\n","# 모델 평가\n","correct = 0\n","total = 0\n","with torch.no_grad():  # 그래디언트 계산 비활성화\n","    for inputs, labels in testloader:\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total  # 정확도 계산\n","print(f'Accuracy on the 10000 test images: {accuracy}%')  # 정확도 출력"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zGy0vU2eSFE","executionInfo":{"status":"ok","timestamp":1707735315996,"user_tz":-540,"elapsed":379712,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"b88a8378-10be-4665-a227-12f6575fa748"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 116998669.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 25411305.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 32061209.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 18531642.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Epoch 1, Train Loss: 0.27169100095828375, Val Loss: 0.09337795337543209\n","Validation Loss Decreased(inf--->0.093378) \t Saving The Model\n","Epoch 2, Train Loss: 0.07873471341840922, Val Loss: 0.06651239539248908\n","Validation Loss Decreased(0.093378--->0.066512) \t Saving The Model\n","Epoch 3, Train Loss: 0.05661494212256123, Val Loss: 0.06045699117338642\n","Validation Loss Decreased(0.066512--->0.060457) \t Saving The Model\n","Epoch 4, Train Loss: 0.04346774993495395, Val Loss: 0.05373844565598274\n","Validation Loss Decreased(0.060457--->0.053738) \t Saving The Model\n","Epoch 5, Train Loss: 0.03558639577108746, Val Loss: 0.046705444876700294\n","Validation Loss Decreased(0.053738--->0.046705) \t Saving The Model\n","Epoch 6, Train Loss: 0.02808920132595813, Val Loss: 0.050020811949891254\n","Epoch 7, Train Loss: 0.02513225558567016, Val Loss: 0.05542768287178912\n","Epoch 8, Train Loss: 0.01880632781004533, Val Loss: 0.04655337812715864\n","Validation Loss Decreased(0.046705--->0.046553) \t Saving The Model\n","Epoch 9, Train Loss: 0.014945876693876927, Val Loss: 0.0528296522848479\n","Epoch 10, Train Loss: 0.013251481866105072, Val Loss: 0.05287841360489999\n","Epoch 11, Train Loss: 0.010977381927378398, Val Loss: 0.04708612915725253\n","Epoch 12, Train Loss: 0.00932584290219044, Val Loss: 0.04415347123815198\n","Validation Loss Decreased(0.046553--->0.044153) \t Saving The Model\n","Epoch 13, Train Loss: 0.006453655993895761, Val Loss: 0.050224725299755094\n","Epoch 14, Train Loss: 0.005056889110948153, Val Loss: 0.04813858149509542\n","Epoch 15, Train Loss: 0.003903841854024601, Val Loss: 0.04601763867691609\n","Epoch 16, Train Loss: 0.0024490715954671033, Val Loss: 0.04541068880541601\n","Epoch 17, Train Loss: 0.0017361578940205315, Val Loss: 0.04377852865598548\n","Validation Loss Decreased(0.044153--->0.043779) \t Saving The Model\n","Epoch 18, Train Loss: 0.0013987856905459922, Val Loss: 0.04508918908691327\n","Epoch 19, Train Loss: 0.0012784649309269297, Val Loss: 0.04449786897756933\n","Epoch 20, Train Loss: 0.0009018127443699389, Val Loss: 0.044774663173944025\n","Accuracy on the 10000 test images: 98.97%\n"]}]},{"cell_type":"markdown","source":["- torch: 이것은 메인 PyTorch 라이브러리입니다. 여기에는 GPU를 통한 가속을 통한 텐서 계산 지원, 신경망 훈련을 용이하게 하는 자동 차별화, 모델 구축 및 훈련을 위한 다양한 유틸리티가 포함됩니다.\n","- torch.nn: 레이어, 활성화 함수, 손실 함수와 같은 신경망의 구성 요소를 제공하는 PyTorch의 하위 모듈입니다. 신경망의 아키텍처를 정의하는 데 필수적입니다.\n","- torch.nn.function: 이 모듈에는 torch.nn 레이어에서 사용되는 기능이 포함되어 있습니다. 입력 데이터 및 가중치에 이러한 함수를 직접 사용할 수 있으므로 일부 작업에 더 많은 유연성을 제공합니다. 여기에는 활성화, 손실 계산 및 상태(즉, 가중치)를 유지하지 않는 다양한 기타 작업을 위한 함수가 포함됩니다.\n","- torch.optim: 이 하위 모듈은 SGD(Stochastic Gradient Descent), Adam 등과 같은 신경망 훈련을 위한 최적화 알고리즘을 제공합니다. 이러한 최적화 프로그램은 계산된 기울기를 기반으로 네트워크의 가중치를 업데이트하는 데 사용됩니다.\n","- torchvision: 이미지 데이터 작업을 위한 유틸리티를 제공하는 PyTorch 프로젝트의 패키지입니다. 여기에는 사전 정의된 데이터세트(예: MNIST, CIFAR10, FashionMNIST), 모델 아키텍처(예: ResNet, AlexNet) 및 전처리를 위한 일반적인 이미지 변환이 포함됩니다.\n","- torchvision.transforms: 일반적인 이미지 변환을 제공하는 torchvision 내의 모듈입니다. 이는 이미지를 신경망에 공급하기 전에 데이터 증대 및 이미지 전처리에 사용될 수 있습니다. 예로는 크기 조정, 정규화, 텐서로 변환 등이 있습니다.\n","- SubsetRandomSampler: 교체 없이 데이터세트에서 요소를 무작위로 샘플링하는 데 사용되는 도구입니다. 데이터 세트를 훈련 및 검증/테스트 세트로 분할하거나 모델 훈련을 위해 사용자 정의 데이터 샘플링 전략을 구현하려는 경우에 특히 유용"],"metadata":{"id":"PDn0y07kIKnU"}},{"cell_type":"markdown","source":["Q. PyTorch를 사용하여 FashionMNIST 데이터세트에 대한 분류 모델링 및 평가를 다음과 같은 단계로 수행하세요.\n","- 1단계: 신경망 모델 정의\n","- 2단계: FashionMNIST 데이터셋 로드\n","- 3단계: 네트워크, 손실 함수, 최적화 알고리즘 초기화\n","- 4단계: 조기 종료를 포함한 모델 학습 및 best model 저장\n","- 5단계: best model을 로드하고 테스트 데이터셋으로 평가"],"metadata":{"id":"hmdHqc6CCdus"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","# 1단계: 신경망 모델 정의\n","# Net 클래스는 nn.Module을 상속받아 만들어진 사용자 정의 신경망 모델로, FashionMNIST 데이터셋의 이미지 분류를 위해 설계\n","class Net(nn.Module):\n","# 모델의 구조를 정의합니다. 이 모델은 세 개의 완전 연결(fully-connected) 레이어를 포함\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 120)  # 입력으로 28x28 크기의 이미지를 받아 펼친 후(784개의 피처), 120개의 출력 노드로 연결\n","        self.fc2 = nn.Linear(120, 84) # 120개의 입력 노드에서 84개의 출력 노드로 연결\n","        self.fc3 = nn.Linear(84, 10)  # 84개의 입력 노드에서 최종적으로 10개의 출력 노드로 연결\n","# forward 메소드는 신경망에 데이터를 어떻게 전달할지 정의\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28) # 입력 이미지 x를 1차원으로 펼치는 과정입니다. -1은 배치 크기에 대응되며, 이는 어떤 크기의 배치라도 처리할 수 있음을 의미\n","        x = F.relu(self.fc1(x)) # 첫 번째 레이어를 통과한 후, ReLU 활성화 함수를 적용합니다. 이는 비선형성을 도입하여 모델이 더 복잡한 패턴을 학습\n","        x = F.relu(self.fc2(x)) # 두 번째 레이어를 통과한 후, 다시 ReLU 활성화 함수를 적용\n","        x = self.fc3(x) # 세 번째 레이어를 통과한 결과를 반환. 소프트맥스 함수 등을 통해 확률로 변환되어 클래스를 예측하는 데 사용\n","        return x\n","\n","# 2단계: FashionMNIST 데이터셋 로드\n","# torchvision 라이브러리를 사용하여 FashionMNIST 데이터셋을 다운로드하고, 데이터를 전처리하기 위한 변환(transform)을 설정하는 과정\n","\n","# transforms.Compose는 여러 전처리 단계를 하나로 묶어주는 역할\n","# transforms.ToTensor(): 이미지를 PyTorch 텐서로 변환. 이미지의 픽셀 값 범위가 0에서 255 사이의 정수에서 0.0에서 1.0 사이의 부동소수점으로 변경\n","# 모든 채널의 평균을 0.5로, 표준편차를 0.5로 설정합니다. 이는 데이터의 범위를 대략적으로 -1.0에서 1.0 사이로 조정\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","# FashionMNIST 데이터셋을 다운로드하고, 지정된 변환을 적용하여 데이터를 준비하는 함수\n","train_val_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# 훈련 및 검증 분할을 위한 데이터 인덱스 생성\n","dataset_size = len(train_val_dataset) # 훈련 및 검증 데이터셋의 전체 크기\n","indices = list(range(dataset_size)) # 데이터셋 내의 모든 샘플에 대한 인덱스를 포함\n","validation_split = 0.1 # 검증 세트로 사용될 데이터의 비율\n","split = int(np.floor(validation_split * dataset_size)) # 검증 세트의 크기를 계산\n","np.random.shuffle(indices) # 훈련 및 검증 세트가 데이터셋의 특정 부분에 치우치지 않도록 하기 위함\n","train_indices, val_indices = indices[split:], indices[:split] # 섞인 인덱스를 사용하여 훈련 세트와 검증 세트의 인덱스를 분할\n","\n","# PT 데이터 샘플러 및 로더 생성\n","# 훈련 세트와 검증 세트에 대한 데이터 로더를 설정하고, 테스트 세트에 대한 데이터 로더를 별도로 설정하는 과정입니다.\n","# 이러한 데이터 로더들은 모델 학습, 검증, 테스트 과정에서 배치 단위로 데이터를 로드하는 데 사용\n","train_sampler = SubsetRandomSampler(train_indices) # train_indices에 해당하는 훈련 데이터의 인덱스를 무작위로 샘플링하는 샘플러를 생성\n","val_sampler = SubsetRandomSampler(val_indices) # val_indices에 해당하는 검증 데이터의 인덱스로부터 데이터를 무작위로 샘플링하는 샘플러를 생성\n","# 배치 크기 4로 로드하는 훈련 데이터 로더를 생성(# 데이터의 무작위 샘플링을 수행)\n","trainloader = torch.utils.data.DataLoader(train_val_dataset, batch_size=4, sampler=train_sampler)\n","valloader = torch.utils.data.DataLoader(train_val_dataset, batch_size=4, sampler=val_sampler)\n","# shuffle=False 인자를 통해 셔플링 없이 순서대로 데이터를 로드. 테스트 과정에서는 데이터의 순서가 결과에 영향을 미치지 않으므로 셔플링을 수행하지 않습니다.\n","testloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)\n","\n","# 3단계: 네트워크, 손실 함수, 최적화 알고리즘 초기화\n","net = Net() #  클래스의 인스턴스를 생성하여 net 변수에 할당\n","criterion = nn.CrossEntropyLoss() # 멀티클래스 분류 문제에서 널리 사용되는 손실 함수로, 모델의 예측값과 실제 타겟값 사이의 차이를 측정\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 모멘텀은 최적화 과정에서 이전 그래디언트의 방향을 고려, 파라미터 업데이트 시 관성을 부여\n","\n","# 4단계: 조기 종료를 포함한 모델 학습\n","patience = 5 # 검증 손실이 개선되지 않을 때, 훈련을 계속 진행하기 전에 기다릴 에폭 수를 의미\n","patience_counter = 0\n","best_val_loss = np.Inf # 최고의 검증 손실 값을 무한대로 초기화. 훈련 과정에서 검증 손실이 이전에 기록된 최소 손실보다 낮아지면 업데이트되는 값\n","\n","# 모델을 에폭 단위로 반복 훈련시키면서, 각 배치의 손실을 계산하고 모델 파라미터를 업데이트하는 기본적인 훈련 과정을 구현\n","for epoch in range(10):  # 데이터셋을 여러 번 반복\n","    net.train()  # 모델을 학습 모드로 설정. 이는 모델 내의 특정 레이어(예: 드롭아웃, 배치 정규화 등)가 훈련 시와 평가 시 다르게 동작해야 할 때 필요\n","    running_loss = 0.0 # 현재 에폭의 총 손실을 계산하기 위해 실행 손실을 0으로 초기화\n","    for i, data in enumerate(trainloader, 0): # '0'은 열거의 시작 인덱스를 지정\n","        inputs, labels = data\n","        optimizer.zero_grad() # 최적화를 수행하기 전에 모델의 그래디언트를 0으로 초기화\n","        outputs = net(inputs) # 현재 배치의 입력 데이터를 모델에 전달하여 예측값을 계산\n","        loss = criterion(outputs, labels) # 모델의 예측값과 실제 레이블 간의 손실을 계산\n","        loss.backward() # 손실 함수의 그래디언트를 역전파합니다. 이 과정에서 모델 파라미터에 대한 손실의 미분값이 계산\n","        optimizer.step() # 계산된 그래디언트를 사용하여 모델의 파라미터를 업데이트\n","        running_loss += loss.item() # 현재 배치의 손실을 실행 손실에 누적. 이를 통해 전체 에폭의 평균 손실을 계산\n","\n","    # 검증 단계\n","    net.eval()  # 모델을 평가 모드로 설정\n","    val_loss = 0.0 # 검증 손실을 계산하기 위한 변수를 0으로 초기화\n","    with torch.no_grad(): # 이 블록 내에서는 그래디언트 계산을 비활성화. 평가 모드에서는 모델을 업데이트하지 않으므로, 그래디언트를 계산할 필요가 없습니다\n","        for inputs, labels in valloader: # 검증 데이터 로더(valloader)에서 배치 단위로 데이터를 로드하여 반복\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels) # criterion은 손실 함수로, 모델의 성능을 측정하는 기준\n","            val_loss += loss.item() # 누적된 검증 손실을 검증 데이터 배치의 총 수로 나누어 평균 검증 손실을 계산\n","\n","    val_loss /= len(valloader)\n","    print(f'에폭 {epoch + 1}, 훈련 손실: {running_loss / len(trainloader)}, 검증 손실: {val_loss}')\n","\n","    # 조기 종료 체크\n","    if val_loss < best_val_loss: # 현재 에폭에서 계산된 검증 손실(val_loss)이 이전에 기록된 최소 검증 손실(best_val_loss)보다 낮은지 확인\n","        print(f'검증 손실이 감소하였습니다. ({best_val_loss:.6f} 에서 {val_loss:.6f}로). 모델 저장 중...')\n","        torch.save(net.state_dict(), '/content/drive/MyDrive/Colab Notebooks/kd_project/models/best_model.pth')\n","        best_val_loss = val_loss\n","        patience_counter = 0\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= patience:\n","            print('조기 종료 발동.')\n","            break\n","\n","# 5단계: 최고의 모델을 로드하고 테스트 데이터셋으로 평가\n","# torch.load 함수는 지정된 경로에서 모델 파라미터를 불러오며, load_state_dict 메서드를 사용하여 이 파라미터를 현재 net 모델에 로드\n","net.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/kd_project/models/best_model.pth'))\n","correct = 0 # 정확히 분류된 샘플의 수를 세기 위한 변수\n","total = 0 # 테스트셋의 전체 샘플 수를 세기 위한 변수\n","with torch.no_grad():\n","    for data in testloader: # 테스트 데이터셋을 배치 단위로 순회\n","        images, labels = data\n","        outputs = net(images) # 현재 배치의 이미지를 모델에 전달하여 예측값을 계산\n","        _, predicted = torch.max(outputs.data, 1) # torch.max는 각 예측에 대한 최대값과 그 위치(인덱스)를 반환. 위치만 필요하므로 _를 사용하여 최대값은 무시\n","        total += labels.size(0) # labels.size(0)는 현재 배치의 크기(샘플 수)\n","        correct += (predicted == labels).sum().item() # 일치하는 경우의 수를 텐서 형태로 반환하며, .item()으로 이를 파이썬의 스칼라 값으로 변환\n","\n","print(f'10000개의 테스트 이미지에 대한 네트워크의 정확도: {100 * correct / total} %')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BnnvmUNyDqQd","executionInfo":{"status":"ok","timestamp":1707653894479,"user_tz":-540,"elapsed":300501,"user":{"displayName":"박기범","userId":"02463368005182404234"}},"outputId":"d59dce3d-8166-4eb9-c7f4-fcc7b429e13f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["에폭 1, 훈련 손실: 0.5361356424116228, 검증 손실: 0.4147784432672585\n","검증 손실이 감소하였습니다. (inf 에서 0.414778로). 모델 저장 중...\n","에폭 2, 훈련 손실: 0.3928052689871213, 검증 손실: 0.36566980215266814\n","검증 손실이 감소하였습니다. (0.414778 에서 0.365670로). 모델 저장 중...\n","에폭 3, 훈련 손실: 0.352077518612075, 검증 손실: 0.4250006926593827\n","에폭 4, 훈련 손실: 0.32682427865016433, 검증 손실: 0.34593992662386486\n","검증 손실이 감소하였습니다. (0.365670 에서 0.345940로). 모델 저장 중...\n","에폭 5, 훈련 손실: 0.3079291260770507, 검증 손실: 0.3171539925446511\n","검증 손실이 감소하였습니다. (0.345940 에서 0.317154로). 모델 저장 중...\n","에폭 6, 훈련 손실: 0.29179519376307084, 검증 손실: 0.3220596654096153\n","에폭 7, 훈련 손실: 0.2794181084287468, 검증 손실: 0.31901972460288863\n","에폭 8, 훈련 손실: 0.26670340754926425, 검증 손실: 0.32035216963128915\n","에폭 9, 훈련 손실: 0.25744489532434206, 검증 손실: 0.3150109196861916\n","검증 손실이 감소하였습니다. (0.317154 에서 0.315011로). 모델 저장 중...\n","에폭 10, 훈련 손실: 0.24640687478282605, 검증 손실: 0.3320030701239684\n","10000개의 테스트 이미지에 대한 네트워크의 정확도: 87.74 %\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","\n","# 가상 데이터 생성 함수\n","def generate_data(num_samples=1000, seq_length=10):\n","    vocab_size = 100  # 어휘집 크기\n","    data = torch.randint(0, vocab_size, (num_samples, seq_length))\n","    labels = torch.randint(0, 2, (num_samples,))  # 0 또는 1의 레이블\n","    return data, labels\n","\n","data, labels = generate_data()\n","\n","# 텐서 데이터셋 및 데이터 로더 생성\n","dataset = TensorDataset(data, labels)\n","train_size = int(0.7 * len(dataset))\n","val_size = int(0.15 * len(dataset))\n","test_size = len(dataset) - (train_size + val_size)\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# LSTM 모델 클래스 정의\n","class LSTMModel(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n","        super(LSTMModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, text):\n","        embedded = self.embedding(text)\n","        lstm_out, (hidden, _) = self.lstm(embedded)\n","        hidden = hidden[-1,:,:]\n","        return self.fc(hidden)\n","\n","model = LSTMModel(vocab_size=100, embed_dim=50, hidden_dim=100, output_dim=1)\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","# 훈련 함수\n","def train(model, train_loader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    for data, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(data).squeeze(1)\n","        loss = criterion(outputs, labels.float())\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_loader)\n","\n","# 평가 함수\n","def evaluate(model, data_loader, criterion):\n","    model.eval()\n","    total_loss = 0\n","    total_accuracy = 0\n","    with torch.no_grad():\n","        for data, labels in data_loader:\n","            outputs = model(data).squeeze(1)\n","            loss = criterion(outputs, labels.float())\n","            total_loss += loss.item()\n","            predictions = torch.round(torch.sigmoid(outputs))\n","            correct_predictions = (predictions == labels.unsqueeze(1)).float()\n","            total_accuracy += correct_predictions.sum().item()\n","    return total_loss / len(data_loader), total_accuracy / len(data_loader.dataset)\n","\n","# 조기 종료 로직을 포함한 훈련 및 검증 과정\n","best_val_loss = float('inf')\n","patience = 3\n","trials = 0\n","\n","for epoch in range(20):\n","    train_loss = train(model, train_loader, optimizer, criterion)\n","    val_loss, val_accuracy = evaluate(model, val_loader, criterion)\n","    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        trials = 0\n","        torch.save(model.state_dict(), 'best_model.pth')\n","    else:\n","        trials += 1\n","        if trials >= patience:\n","            print(\"조기 종료 발생\")\n","            break\n","\n","# 테스트 데이터로 최고 모델 평가\n","model.load_state_dict(torch.load('best_model.pth'))\n","test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n","print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qp76Txx5DSzo","executionInfo":{"status":"ok","timestamp":1707670126856,"user_tz":-540,"elapsed":1060,"user":{"displayName":"박기범","userId":"02463368005182404234"}},"outputId":"66f0e059-ee9e-43dc-aead-16c053dcf6e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Loss: 0.6938, Val Loss: 0.6977, Val Accuracy: 15.0133\n","Epoch 2, Train Loss: 0.6783, Val Loss: 0.6946, Val Accuracy: 15.2667\n","Epoch 3, Train Loss: 0.6616, Val Loss: 0.6936, Val Accuracy: 15.3733\n","Epoch 4, Train Loss: 0.6383, Val Loss: 0.7041, Val Accuracy: 15.3600\n","Epoch 5, Train Loss: 0.6014, Val Loss: 0.7069, Val Accuracy: 15.3867\n","Epoch 6, Train Loss: 0.5603, Val Loss: 0.7668, Val Accuracy: 15.0533\n","조기 종료 발생\n","Test Loss: 0.6984, Test Accuracy: 15.0400\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}